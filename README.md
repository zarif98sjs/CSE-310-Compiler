# **`A Compiler in the making`**

A compiler is a computer program that translates computer code written in one programming language (the source language) into another language (the target language). Here we will build some parts of a compiler for the subset of C language.

# Part 1 : **`Creating a Symbol Table`**

The first part needed to make a `Compiler` is a `Symbol Table`. A Symbol Table is a data structure maintained by compilers in order to store information about the occurrence of various entities such as identifiers, objects, function names etc. Information of different entities may include type, value, scope etc. 

At the starting phase of constructing a compiler, we will construct
a Symbol Table which maintains a list of `Hash Tables(Scope Tables)` where each hash table contains information of symbols encountered in a scope of the source program . Each Scope Table will have `Symbol Info` (which will store the information) in it's buckets.

Here is an overview 

![](images/symboltable.png)

Now straight to code . I am showing the declarations here . The full implementation can be found in the code directory.

## `SymbolInfo`

```c++

#ifndef SYMBOLINFO_H
#define SYMBOLINFO_H

#include<bits/stdc++.h>
using namespace std;

struct SymbolInfo
{
    string key;
    string val;
    string var_type;
    vector<string>param_v;
    bool isFunctionDeclaration;
    bool isFunction;

    SymbolInfo* nxt;

    int bucket;
    int bucket_pos;

    SymbolInfo();

    SymbolInfo(string key,string val);
    SymbolInfo(string key,string val,string var_type,vector<string>param_v,bool isFunctionDeclaration,bool isFunction);

    SymbolInfo(string key,string val,string var_type,vector<string>param_v,bool isFunctionDeclaration,bool isFunction,SymbolInfo* nxt);


    void setVarType(string var_type);
};

#endif // SYMBOLINFO_H

```

## `ScopeTable`

```c++

#ifndef SCOPETABLE_H
#define SCOPETABLE_H

#include<bits/stdc++.h>
#include "SymbolInfo.h"
using namespace std;

struct ScopeTable
{
    string id;
    int counter;

    ScopeTable* parentScope;

    int M; /* initial hast table size */

    vector<SymbolInfo*>ht;

    function<int(string)> hashValue;

    template<typename T>
    ScopeTable(int table_size,T func)
    {
        id = "1";
        counter = 1;
        parentScope = NULL;

        M = table_size;
        hashValue = func;

        ht = vector<SymbolInfo*>(M);
    }

    ~ScopeTable(); /// destructor

    /// id
    string get_id();
    void set_id(string id);

    /// counter
    int get_counter();
    void set_counter(int counter);
    void increase_counter();

    /// hash
    int hash(string key);

    /// mehtods
    SymbolInfo* search(string key);
    SymbolInfo* insert(SymbolInfo si);
    bool erase(string key);

    /// prints
    void print();
    void printChainLengths();

};

#endif // SCOPETABLE_H

```

## `SymbolTable`

```c++

#ifndef SYMBOLTABLE_H
#define SYMBOLTABLE_H

/* Which of the favors of your Lord will you deny ? */

#include<bits/stdc++.h>
#include "ScopeTable.h"
using namespace std;

template <class T>
string to_str(T x)
{
    stringstream ss;
    ss<<x;
    return ss.str();
}


class SymbolTable
{
    ScopeTable* cur;
    int bucket_size;
    function<int(string)> func;

public:

    template<typename T>
    SymbolTable(int bucket_size,T func) /// constructor
    {
        this->bucket_size = bucket_size;
        this->func = func;

        cur = new ScopeTable(bucket_size,func);
    }

    ~SymbolTable();

    void enter_scope(); /// enter scope  = push : create and push a new ScopeTable
    void exit_scope(); /// exit scope  = pop : remove the current ScopeTable

    bool insert_symbol(SymbolInfo si);
    bool remove_symbol(string key);
    SymbolInfo* lookup(string key);

    void print_current_scope();
    void print_all_scope();

    string getCurScopeTableId();

};

#endif // SYMBOLTABLE_H

```

# Part 2 : `Lexical Analysis`

Lexical analysis is the process of scanning the source program as a sequence of characters and converting them into sequences of tokens. A program that performs this task is called a lexical analyzer or a lexer or a scanner.

Here we will use the tool `flex` to do the lexical analysis. Regex is written to do the lexical analysis with flex.



# Part 3 : `Parser(Syntax Analysis) & Semantic Analysis`

The parser obtains a string of tokens from the lexical analyzer and verifies that the string of token names can be generated by the **grammar** for the source language. The parser should also report any syntax errors in an intelligible fashion and recover from commonly occurring errors to continue processing the remainder of the program. 

To make parser for grammar , we will use the tool **`bison`**.  This greatly reduces our work .

Here is a basic structure of a **`bison`** file 

```c
%{
    user code section 1
%}
    bison declarations
%%
    bison grammar rules
%%
    user code section 2
```

## **User Code**

Codes written in this section is directly copied in the resulting `.c` file (`y.tab.c`). Here we include our previously written `SymbolInfo` `ScopeTable` and `SymbolTable` header files. We can also include custom libraries, constants and so on. Most includes and function prototype declarations happen at the top (_user code section 1_) while their actual definition happens at the bottom (_user code section 2_).

## **Stack**

### **Using `YYSTYPE`**

We can hardcode a specific type for the terminals and non-terminals by defining **`YYSTYPE`**. 

```c++
#define YYSTYPE SymbolInfo*
```

and in the lex file, we can write something like this for the tokens

```c++
{integer}	{
				SymbolInfo *s= new  SymbolInfo(yytext,"CONST_INT");
				yylval = (YYSTYPE)s;
				return CONST_INT;
			}
```

### **Using `union`**

Using **`union`**  we can specify types for the terminals(`token`) and non-terminals(`type`) . We have to tell bison the type of that particular `token` / `type` by declaring it inside a special union like this :

```c++
%union{
    SymbolInfo* symbol_info;
    Helper* helper;
}
```

This `union` tells `bison` that when we use a `token` / `type` that is accompanied by **`symbol_info`** then we can use its value like **`SymbolInfo*`**. On the other hand if its accompanied by **`helper`** then that value will be treated as a
**`Helper*`** instead.

It has to be noted that being a `union` and not a `struct` it also means the values use _shared_ memory and not separate segments as opposed to `struct` fields. We can have as many different tags as we want inside the union and both `tokens` and `types` can have the *same* tag.

## **Token**

Terminals are called `token` in Bison. The tokens must be first declared in the parser. Because the tokens are generated in the `y.tab.h` file, then used in the flex file `scanner.l`. Token declarations must be inside bison's `declaration section`. We can use **`YYSTYPE`** or **`union`** to define token types.


### **Using `YYSTYPE`**

```c++
%token ID ADDOP MULOP RELOP LOGICOP
```

### **Using `union`**

```c++
%token < symbol_info > ID ADDOP MULOP RELOP LOGICOP
```

## **Type**

Non-terminals are called `type` in Bison. These non-terminals/state can have a return value, much like `tokens`. We can use **`YYSTYPE`** or **`union`** to define types in the same way.


### **Using `YYSTYPE`**

```c++
%type start program unit variable var_declaration type_specifier
```

### **Using `union`**

```c++
%type < helper > start program unit variable var_declaration type_specifier
```

## **Grammar**

In `bison` we create a *grammar* which syntactically evaluates if the `tokens` that `flex` generated are emitted in a syntactically correct order. In order to do that we will have to take a good look at our language specification and break it down to building blocks that we then have to express using `bison` rules.

Grammar rules in general have the following syntax:

```c++
rule_name:
    caseA
    | caseB
        .
        .
    | caseN
    ;
```

A rule starts by typing its _unique_ name then a colon (`:`) followed by a number of cases which are separated
with a dash `|`; the last rule *must* be followed by a semicolon (`;`). Also rules don't have to be separated
by lines so this would be perfectly legal as well:

```c
rule_name: caseA | caseB | ... | caseN;
```

It is also possible to write action codes:

```c++
func_declaration : type_specifier ID LPAREN parameter_list RPAREN { /** can write code here : known as action code **/ } SEMICOLON
```

The grammar we will use here is the following :

```c++
start : program
	{
		//write your code in this block in all the similar blocks below
	}
	;

program : program unit 
	| unit
	;
	
unit : var_declaration
     | func_declaration
     | func_definition
     ;
     
func_declaration : type_specifier ID LPAREN parameter_list RPAREN SEMICOLON
		| type_specifier ID LPAREN RPAREN SEMICOLON
		;
		 
func_definition : type_specifier ID LPAREN parameter_list RPAREN compound_statement
		| type_specifier ID LPAREN RPAREN compound_statement
 		;				


parameter_list  : parameter_list COMMA type_specifier ID
		| parameter_list COMMA type_specifier
 		| type_specifier ID
		| type_specifier
 		;

 		
compound_statement : LCURL statements RCURL
 		    | LCURL RCURL
 		    ;
 		    
var_declaration : type_specifier declaration_list SEMICOLON
 		 ;
 		 
type_specifier	: INT
 		| FLOAT
 		| VOID
 		;
 		
declaration_list : declaration_list COMMA ID
 		  | declaration_list COMMA ID LTHIRD CONST_INT RTHIRD
 		  | ID
 		  | ID LTHIRD CONST_INT RTHIRD
 		  ;
 		  
statements : statement
	   | statements statement
	   ;
	   
statement : var_declaration
	  | expression_statement
	  | compound_statement
	  | FOR LPAREN expression_statement expression_statement expression RPAREN statement
	  | IF LPAREN expression RPAREN statement
	  | IF LPAREN expression RPAREN statement ELSE statement
	  | WHILE LPAREN expression RPAREN statement
	  | PRINTLN LPAREN ID RPAREN SEMICOLON
	  | RETURN expression SEMICOLON
	  ;
	  
expression_statement 	: SEMICOLON			
			| expression SEMICOLON 
			;
	  
variable : ID 		
	 | ID LTHIRD expression RTHIRD 
	 ;
	 
 expression : logic_expression	
	   | variable ASSIGNOP logic_expression 	
	   ;
			
logic_expression : rel_expression 	
		 | rel_expression LOGICOP rel_expression 	
		 ;
			
rel_expression	: simple_expression 
		| simple_expression RELOP simple_expression	
		;
				
simple_expression : term 
		  | simple_expression ADDOP term 
		  ;
					
term :	unary_expression
     |  term MULOP unary_expression
     ;

unary_expression : ADDOP unary_expression  
		 | NOT unary_expression 
		 | factor 
		 ;
	
factor	: variable 
	| ID LPAREN argument_list RPAREN
	| LPAREN expression RPAREN
	| CONST_INT 
	| CONST_FLOAT
	| variable INCOP 
	| variable DECOP
	;
	
argument_list : arguments
			  |
			  ;
	
arguments : arguments COMMA logic_expression
	      | logic_expression
	      ;
```

## **Accessing `token` and `types`**

Flex returns `tokens` to parser. Parser tries to match grammar rules by shifting one by one and reduced when a rule is matched. `Token` and `types` can be accessed using `$1`, `$2`, ... `$n` where n is the nth item of the rule. Each rule can return a value which is `$$`

```c++
arguments : arguments COMMA logic_expression
    ^           ^       ^           ^
    $$          $1      $2          $3
```

## **Precedence**

There are 4 types of precedence types in `bison` , 3 of which declare both precedence as well as associativity while the last (as its name suggests) declares only precedence. The complete list is the following:

- **`%left`**: Indicates that this operator has *left* associativity (e.g. (a + b) + c is preferred)
    - syntax is: `%left symbols`
- **`%right`**: Indicates that this operator has *right* associativity (e.g. a + (b + c) is preferred)
    - syntax is: `%right symbols`
- **`%nonassoc`**: Indicates that this operator **cannot be seen in sequence** and is considered a *syntax error*
if that's encountered (e.g. a + b + c would throw an error).
    - syntax is: `%nonassoc symbols`
- **`%precedence`**: Indicates just precedence **not** associativity.

## **`Shift/Reduce` Conflict**

This type of conflict happens when `bison` does not know which operation to perform, `shift` or `reduce`. The given grammar has one example of this type of conflict :

```c++
statement : IF LPAREN expression RPAREN statement
	      | IF LPAREN expression RPAREN statement ELSE statement
```

The example of this would be :

```c++
if(x<2) if(x>0) y = 2; else z = 5;
```

Because of the ambiguity, the parser doesn't know if he needs associate the `else` statement with the most recent `if` or not. That is it does not know if it already needs to reduce or continue to process the token `ELSE`

We can solve this using 2 ways:
- rewrite the grammar 
- assign precedence to token 

The first part can be a tough job. Bison gives the opportunity to do the 2nd one.

We can solve this shift/reduce conflict by adding the following in the declaration section:

```c++
%nonassoc LOWER_THAN_ELSE
%nonassoc ELSE
```

and change the grammar rule to this:

```c++
statement : IF LPAREN expression RPAREN statement %prec LOWER_THAN_ELSE
	      | IF LPAREN expression RPAREN statement ELSE statement
```

Here, we are using a dummy token `LOWER_THAN_ELSE` and putting it before `ELSE`, thus making `ELSE` the higher priority one.

## **Freeing Memory : Part 1**


## **Freeing Memory : Part 2**



# Part 4 : `Error Recovery`